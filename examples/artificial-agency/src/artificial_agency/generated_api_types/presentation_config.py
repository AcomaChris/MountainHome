# code generated by src/bagel/scripts/dump_client_models.py - do not edit manually.

from __future__ import annotations

from typing import Any, Dict, List, Optional

from pydantic import ConfigDict, Field, RootModel

from artificial_agency._types import GeneratedModel


class Model(RootModel[Any]):
    root: Any


class PresentationOrderItem(RootModel[List]):
    root: List = Field(..., max_length=2, min_length=2)


class PresentationConfig(GeneratedModel):
    model_config = ConfigDict(
        extra='allow',
    )
    token_limits: Optional[Dict[str, int]] = Field(
        default={},
        description='Maximum number of tokens for each category of content.  There are two built-in categories: `function` and `cue`. The `function` category is used to limit the size of function definitions passed to the `generate_function_call` endpoint.  The `cue` category is used to limit the size of the cue passed to all generation endpoints. Other categories are client-defined strings, and can be set in the `token_category` field of component configurations to apply this limit to that component.  All components with the same `token_category` count against the same limit.  If a category limit is reached, subsequent content in that category will be truncated if possible. If truncation is not possible, the generation request will be rejected as invalid.',
        title='Token Limits',
    )
    presentation_order: Optional[List[PresentationOrderItem]] = Field(
        default=[],
        description="Ordering of presentation elements to use when building LLM interactions. Each list entry is a pair of (component_id, presentation_element). component_id must be the id of a component from component_configs. presentation_element must be one of the presentation elements supported by the component's type.",
        title='Presentation Order',
    )
